{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these types of machine learning problems to predict fuel efficiency, we aim to predict the output of a continuous value, such as a price or a probability. In this programming lab, I will take you through how we can predict Fuel Efficiency with Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Fuel Efficiency\n",
    "Here we will use one of the famous datasets among machine learning practitioners, Auto MPG dataset to create a model to predict fuel efficiency of vehicles in the late 1970s and early 1980s. To do this, we will provide the model with a description of many automobiles from this period. This description includes attributes such as cylinders, displacement, horsepower and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s import the necessary libraries to get started with this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the next thing to do is to download the dataset. let’s import the data using the pandas package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./auto.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “origin” column in the dataset is categorical, so to move forward we need to use some one-hot encoding on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('origin')\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      chevrolet chevelle malibu\n",
       "1              buick skylark 320\n",
       "2             plymouth satellite\n",
       "3                  amc rebel sst\n",
       "4                    ford torino\n",
       "                 ...            \n",
       "393              ford mustang gl\n",
       "394                    vw pickup\n",
       "395                dodge rampage\n",
       "396                  ford ranger\n",
       "397                   chevy s-10\n",
       "Name: car name, Length: 398, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.pop('car name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will separate the target values from the features in the dataset. This label is that feature that we will use to train the model to predict fuel efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('mpg')\n",
    "test_labels = test_dataset.pop('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normilize Data\n",
    "\n",
    "It is recommended that you standardize features that use different scales and ranges. Although the model can converge without standardization of features, this makes learning more difficult and makes the resulting model dependent on the choice of units used in the input. We need to do this to project the test dataset into the same distribution the model was trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>USA</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>153</td>\n",
       "      <td>4129</td>\n",
       "      <td>13.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2542</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>4294</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2979</td>\n",
       "      <td>19.5</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "65           8         351.0        153    4129          13.0          72   \n",
       "132          4         140.0         75    2542          17.0          74   \n",
       "74           8         302.0        140    4294          16.0          72   \n",
       "78           4         120.0         87    2979          19.5          72   \n",
       "37           6         232.0        100    3288          15.5          71   \n",
       "\n",
       "     USA  Europe  Japan  \n",
       "65   1.0     0.0    0.0  \n",
       "132  1.0     0.0    0.0  \n",
       "74   1.0     0.0    0.0  \n",
       "78   0.0     1.0    0.0  \n",
       "37   1.0     0.0    0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    # apply normalization techniques \n",
    "    for column in df.columns: \n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()   \n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 1537514087100696590150110?658854145808290105691907897112701166688841101109272701109690155711982201658010096110901801076776831307617020011088841407872100951801481981058321567155871009575756160180150607846746784120716370225975267129165758517585528892659010517515098907013065868965158145651701001509514072756883851508311095605265857811090909315062120150230671128685180140103?901251151001006811010592105175867510053112149588872751526213015070951108853138110704863210150150170108?96150888092851158410070139208907517567671509012911590851538890697011097225?1456778981101671058012084758815015092949714595979715072487571105140639060115461057015012595769290686486?861051607715068888880150959088909067122110165708014011317013011074100678810021588225681001609088102681007578 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1603\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[0;32m   1604\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1605\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '1537514087100696590150110?658854145808290105691907897112701166688841101109272701109690155711982201658010096110901801076776831307617020011088841407872100951801481981058321567155871009575756160180150607846746784120716370225975267129165758517585528892659010517515098907013065868965158145651701001509514072756883851508311095605265857811090909315062120150230671128685180140103?901251151001006811010592105175867510053112149588872751526213015070951108853138110704863210150150170108?96150888092851158410070139208907517567671509012911590851538890697011097225?1456778981101671058012084758815015092949714595979715072487571105140639060115461057015012595769290686486?861051607715068888880150959088909067122110165708014011317013011074100678810021588225681001609088102681007578'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1607\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1607\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[0;32m   1608\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1609\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ziana-pc\\Desktop\\NLP_LABS\\LAB_2\\predict_fuel.ipynb Cell 18\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m normed_train_data \u001b[39m=\u001b[39m norm(train_dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m normed_test_data \u001b[39m=\u001b[39m norm(test_dataset)\n",
      "\u001b[1;32mc:\\Users\\ziana-pc\\Desktop\\NLP_LABS\\LAB_2\\predict_fuel.ipynb Cell 18\u001b[0m line \u001b[0;36mnorm\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnorm\u001b[39m(df):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# apply normalization techniques \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns: \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         df[column] \u001b[39m=\u001b[39m (df[column] \u001b[39m-\u001b[39m df[column]\u001b[39m.\u001b[39;49mmean()) \u001b[39m/\u001b[39m df[column]\u001b[39m.\u001b[39mstd()   \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:10751\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10740\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m  10741\u001b[0m     _num_doc,\n\u001b[0;32m  10742\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10749\u001b[0m )\n\u001b[0;32m  10750\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, skipna\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, numeric_only\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m> 10751\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:10369\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, skipna\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, numeric_only\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m> 10369\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_function(\n\u001b[0;32m  10370\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanmean, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  10371\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:10354\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10344\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m  10345\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m  10346\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10349\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m  10350\u001b[0m     )\n\u001b[0;32m  10351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_by_level(\n\u001b[0;32m  10352\u001b[0m         name, axis\u001b[39m=\u001b[39maxis, level\u001b[39m=\u001b[39mlevel, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[0;32m  10353\u001b[0m     )\n\u001b[1;32m> 10354\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  10355\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[0;32m  10356\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4392\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4388\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4389\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not implement numeric_only.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4390\u001b[0m     )\n\u001b[0;32m   4391\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 4392\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:94\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 94\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     95\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     96\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:156\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    154\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    158\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:411\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 411\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    414\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:666\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    663\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    665\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[1;32m--> 666\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    669\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1610\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1607\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[0;32m   1608\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1609\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1610\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 1537514087100696590150110?658854145808290105691907897112701166688841101109272701109690155711982201658010096110901801076776831307617020011088841407872100951801481981058321567155871009575756160180150607846746784120716370225975267129165758517585528892659010517515098907013065868965158145651701001509514072756883851508311095605265857811090909315062120150230671128685180140103?901251151001006811010592105175867510053112149588872751526213015070951108853138110704863210150150170108?96150888092851158410070139208907517567671509012911590851538890697011097225?1456778981101671058012084758815015092949714595979715072487571105140639060115461057015012595769290686486?861051607715068888880150959088909067122110165708014011317013011074100678810021588225681001609088102681007578 to numeric"
     ]
    }
   ],
   "source": [
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                640       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,865\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "  return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before training the model to predict fuel efficiency let’s try this model in the first 10 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ziana-pc\\Desktop\\NLP_LABS\\LAB_2\\predict_fuel.ipynb Cell 22\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m example_batch \u001b[39m=\u001b[39m train_dataset[:\u001b[39m10\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m example_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(example_batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ziana-pc/Desktop/NLP_LABS/LAB_2/predict_fuel.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m example_result\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ziana-pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "example_batch = train_dataset[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
